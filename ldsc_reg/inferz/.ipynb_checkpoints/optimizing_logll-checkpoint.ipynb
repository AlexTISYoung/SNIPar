{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sib_ldsc_z' from 'C:\\\\Users\\\\Hariharan\\\\Documents\\\\git_repos\\\\SNIPar\\\\ldsc_reg\\\\inferz\\\\sib_ldsc_z.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sib_ldsc_z as ld\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import comb\n",
    "from scipy.misc import derivative\n",
    "import scipy.stats\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import glob\n",
    "from numba import jit, njit, prange\n",
    "reload(ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning there is no value for z. Maybe consider simulating it\n",
      "No value for U given. Generating a vector of ones (all SNPs weighted equally)\n",
      "No value for r given. Generating a vector of ones for r\n",
      "Warning: No value given for allele frequencies. Some parameters won't be normalized.\n",
      "Simulated LD scores!\n",
      "Effect Vectors Simulated!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "N = int(1e4)\n",
    "S = np.array([[[1e-4, -5 * 1e-5], [-5 * 1e-5, 1e-4]]] * N)\n",
    "V = np.array([[0.5, 0.25], [0.25, 0.5]])\n",
    "\n",
    "model = ld.sibreg(S = S)\n",
    "model.simdata(V/N, N, simr = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hariharan\\Documents\\git_repos\\SNIPar\\ldsc_reg\\inferz\\sib_ldsc_z.py:242: NumbaPerformanceWarning: \u001b[1m\u001b[1m\u001b[1m'@' is faster on contiguous arrays, called on (array(float64, 2d, F), array(float64, 2d, A))\u001b[0m\u001b[0m\u001b[0m\n",
      "  log_ll[i] = (1/ui) * _log_ll(V_norm , zi, Si, ri)\n",
      "C:\\Users\\Hariharan\\Documents\\git_repos\\SNIPar\\ldsc_reg\\inferz\\sib_ldsc_z.py:242: NumbaPerformanceWarning: \u001b[1m\u001b[1m'@' is faster on contiguous arrays, called on (array(float64, 2d, F), array(float64, 2d, A))\u001b[0m\u001b[0m\n",
      "  log_ll[i] = (1/ui) * _log_ll(V_norm , zi, Si, ri)\n",
      "C:\\Users\\Hariharan\\Documents\\git_repos\\SNIPar\\ldsc_reg\\inferz\\sib_ldsc_z.py:243: NumbaPerformanceWarning: \u001b[1m\u001b[1m\u001b[1m'@' is faster on contiguous arrays, called on (array(float64, 2d, C), array(float64, 2d, A))\u001b[0m\u001b[0m\u001b[0m\n",
      "  Gvec[i, :, :] = (1/ui) * _grad_ll_v(V_norm, zi, Si, ri)\n",
      "C:\\Users\\Hariharan\\Documents\\git_repos\\SNIPar\\ldsc_reg\\inferz\\sib_ldsc_z.py:243: NumbaPerformanceWarning: \u001b[1m\u001b[1m'@' is faster on contiguous arrays, called on (array(float64, 2d, C), array(float64, 2d, A))\u001b[0m\u001b[0m\n",
      "  Gvec[i, :, :] = (1/ui) * _grad_ll_v(V_norm, zi, Si, ri)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(38631.03860184946, array([[-140.90639708,  -82.11590935],\n",
       "        [ -82.11590935,  125.08515464]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.neg_logll_grad(V, model.z, model.S, model.u, model.r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hariharan\\Documents\\git_repos\\SNIPar\\ldsc_reg\\inferz\\sib_ldsc_z.py:150: NumbaPerformanceWarning: \u001b[1m\u001b[1m'@' is faster on contiguous arrays, called on (array(float64, 2d, F), array(float64, 2d, A))\u001b[0m\u001b[0m\n",
      "  - (1/2) * z.T @ Sigma_inv @ z)\n",
      "C:\\Users\\Hariharan\\Anaconda3\\lib\\site-packages\\numba\\typing\\npydecl.py:967: NumbaPerformanceWarning: \u001b[1m'@' is faster on contiguous arrays, called on (array(float64, 2d, F), array(float64, 2d, A))\u001b[0m\n",
      "  warnings.warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-11.68651716929529"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld._log_ll(V, model.z[0, :], model.S[0], model.r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No initial guess provided.\n",
      "Making 'optimal' matrix\n",
      "=================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.52262128, 0.26207389],\n",
       "        [0.26207389, 0.48484274]]),       fun: 38627.52359063335\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([ 2.43951351e-05, -1.33080442e-05,  7.36192092e-05])\n",
       "   message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "      nfev: 48\n",
       "       nit: 17\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([0.52262128, 0.26207389, 0.48484274]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bounds(n):\n",
    "    \n",
    "    # =============================== #\n",
    "    # From a number n, the function\n",
    "    # outputs a list of bounds\n",
    "    # for a var cov matrix of size\n",
    "    # n x n\n",
    "    # =============================== #\n",
    "    \n",
    "    # extract idx of flat array whcih are diagonals\n",
    "    uptriangl_idx = np.array(np.triu_indices(n))\n",
    "    diags = uptriangl_idx[0, :] == uptriangl_idx[1, :]\n",
    "    \n",
    "    # Construct list of bounds\n",
    "    bounds_list = np.array([(None, None)] * len(diags))\n",
    "    bounds_list[diags] = (1e-6, None)\n",
    "    \n",
    "    bounds_list_out = [tuple(i) for i in bounds_list]\n",
    "    \n",
    "    return bounds_list_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def calc_inv_root(S):\n",
    "    '''\n",
    "    A stable solver for S^{-1/2}\n",
    "    '''\n",
    "    \n",
    "    if ~np.any(np.isnan(S)):\n",
    "        S_eig = np.linalg.eig(S)\n",
    "        l = np.zeros(S.shape)\n",
    "        np.fill_diagonal(l,np.power(S_eig[0],-0.5))\n",
    "        S_inv_root = S_eig[1].dot(np.dot(l,S_eig[1].T))\n",
    "    else:\n",
    "        S_inv_root =  np.empty_like(S)\n",
    "        S_inv_root[:] = np.nan\n",
    "    return S_inv_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_upper_triangle(x):\n",
    "    \n",
    "    # =============================== #\n",
    "    # Extracts the upper triangular portion of \n",
    "    # a symmetric matrix\n",
    "    # =============================== #\n",
    "    \n",
    "    n, m = x.shape\n",
    "    assert n == m\n",
    "    \n",
    "    upper_triangle = x[np.triu_indices(n)]\n",
    "    \n",
    "    return upper_triangle\n",
    "\n",
    "def return_to_symmetric(triangle_vec, final_size):\n",
    "    \n",
    "    # =============================== #\n",
    "    # Given a vector of the upper triangular matrix,\n",
    "    # get back the symmetric matrix\n",
    "    # =============================== #\n",
    "    \n",
    "    X = np.zeros((final_size,final_size))\n",
    "    X[np.triu_indices(X.shape[0], k = 0)] = triangle_vec\n",
    "    X = X + X.T - np.diag(np.diag(X))\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'njit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5712ba8a02bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m@\u001b[0m\u001b[0mnjit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_log_ll_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \"\"\"\n\u001b[0;32m      5\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlog\u001b[0m \u001b[0mlikelihood\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mSNP\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mformulated\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'njit' is not defined"
     ]
    }
   ],
   "source": [
    "@njit\n",
    "def _log_ll_vec(V, z, S, r):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns the log likelihood matrix for a given SNP i as formulated by:\n",
    "\n",
    "    .. math::\n",
    "        l_i = -\\frac{d}{2} log (2 \\pi) - \\frac{1}{2} log ( |I + r_i S_i^{-1/2} V S_i^{-1/2}| ) -\n",
    "                \\frac{1}{2} z_i^T (I + r_i S_i^{-1/2} V S_i^{-1/2}) ^{-1} z_i\n",
    "\n",
    "    Inputs:\n",
    "    V = dxd numpy matrix\n",
    "    z = dx1 numpy matrix\n",
    "    S = dxd numpy matrix\n",
    "    r = scalar\n",
    "    f = scalar\n",
    "\n",
    "    Outputs:\n",
    "    logll = scalar\n",
    "    \"\"\"\n",
    "\n",
    "    S_inv_root = calc_inv_root(S)\n",
    "    Sigma = np.identity(S.shape[0])+r*np.dot(S_inv_root.dot(V),S_inv_root)\n",
    "    logdet = np.linalg.slogdet(Sigma)\n",
    "\n",
    "    det = np.linalg.det(Sigma)\n",
    "    if det > 1e-6 or det < -1e-6:\n",
    "        Sigma_inv = np.linalg.inv(Sigma)\n",
    "    else:\n",
    "        Sigma_inv = np.linalg.pinv(Sigma)\n",
    "\n",
    "    z = z.reshape(V.shape[0],1)\n",
    "    d = V.shape[0]\n",
    "\n",
    "    L = - (d/2) * np.log(2 * np.pi) \\\n",
    "        - (1/2) * logdet[0]*logdet[1] \\\n",
    "        - (1/2) * np.dot(z.T,Sigma_inv.dot(z))\n",
    "\n",
    "    return L[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'njit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a14bcf696e6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m@\u001b[0m\u001b[0mnjit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_grad_ll_v\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \"\"\"\n\u001b[0;32m      5\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlog\u001b[0m \u001b[0mlikelihood\u001b[0m \u001b[0mwrt\u001b[0m \u001b[0mV\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mSNP\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mformulated\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'njit' is not defined"
     ]
    }
   ],
   "source": [
    "@njit\n",
    "def _grad_ll_v(V, z, S, r):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns the gradient of the log likelihood wrt V for a given SNP i as formulated by:\n",
    "\n",
    "    .. math::\n",
    "        \\frac{dl}{dV} = S^{-1/2} \\Sigma_i^{-1} (\\Sigma - z_i z_i^T) \\Sigma_i^{-1} S^{-1/2}\n",
    "\n",
    "    Inputs:\n",
    "    V = dxd numpy matrix\n",
    "    z = dx1 numpy matrix\n",
    "    S = dxd numpy matrix\n",
    "    u = 1 numpy matrix\n",
    "    r = 1 numpy matrix\n",
    "    f = 1 numpy matrix\n",
    "\n",
    "    Outputs:\n",
    "    grad_ll_v = dxd matrix \n",
    "    \"\"\"\n",
    "\n",
    "    S_inv_root = calc_inv_root(S)\n",
    "    Sigma = np.identity(S.shape[0])+r*np.dot(S_inv_root.dot(V),S_inv_root)\n",
    "\n",
    "    det = np.linalg.det(Sigma)\n",
    "    if det > 1e-6 or det < -1e-6:\n",
    "        Sigma_inv = np.linalg.inv(Sigma)\n",
    "    else:\n",
    "        Sigma_inv = np.linalg.pinv(Sigma)\n",
    "\n",
    "    z = z.reshape(z.shape[0],1)\n",
    "    SSigma_inv = S_inv_root.dot(Sigma_inv)\n",
    "    g = r * SSigma_inv.dot(np.dot(Sigma-z.dot(z.T),SSigma_inv.T))\n",
    "    return -(1/2) * g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel = True)\n",
    "def neg_logll_grad(V, \n",
    "                   z, S, \n",
    "                   u, r, \n",
    "                   f):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns the loglikelihood and its gradient wrt V for a given SNP i as formulated by:\n",
    "\n",
    "    .. math::\n",
    "        l_i = -\\frac{d}{2} log (2 \\pi) - \\frac{1}{2} log ( |I + r_i S_i^{-1/2} V S_i^{-1/2}| ) -\n",
    "                \\frac{1}{2} z_i^T (I + r_i S_i^{-1/2} V S_i^{-1/2}) ^{-1} z_i\n",
    "\n",
    "    and\n",
    "\n",
    "    .. math::\n",
    "        \\frac{dl}{dV} = S^{-1/2} \\Sigma_i^{-1} (\\Sigma - z_i z_i^T) \\Sigma_i^{-1} S^{-1/2}\n",
    "\n",
    "    Inputs:\n",
    "    V = dxd numpy matrix\n",
    "    z = dxN numpy matrix\n",
    "    S = dxd numpy matrix\n",
    "    u = 1 numpy matrix\n",
    "    r = 1 numpy matrix\n",
    "    f = 1 numpy matrix\n",
    "    logllfunc = function which calculates logll\n",
    "                (uses self._log_ll by default)\n",
    "    gradfunc = function which calculated grad of logll\n",
    "                (uses self._grad_ll_v by default)\n",
    "\n",
    "    Outputs:\n",
    "    -log_ll = 1x1 scalar\n",
    "    -Gvec = dxd numpy matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Unflatten V into a matrix\n",
    "    d = S[0].shape[0]\n",
    "    N = len(S)\n",
    "    \n",
    "    Gvec = np.zeros((N, d, d))\n",
    "    log_ll = np.zeros(N)\n",
    "\n",
    "    # Normalizg variables\n",
    "    V_norm = V\n",
    "    for i in prange(N):\n",
    "\n",
    "        Si = S[i]\n",
    "        zi = z[i, :].reshape((d, 1))\n",
    "        ui = u[i]\n",
    "        ri = r[i]\n",
    "\n",
    "        Si = N * Si\n",
    "\n",
    "        log_ll[i] = (1/ui) * _log_ll_vec(V_norm , zi, Si, ri)\n",
    "        Gvec[i, :, :] = (1/ui) * _grad_ll_v(V_norm, zi, Si, ri)\n",
    "\n",
    "    return -log_ll.sum() , -Gvec.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_logll_grad_basic(V, \n",
    "                           z, S, \n",
    "                           u, r, \n",
    "                           f):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns the loglikelihood and its gradient wrt V for a given SNP i as formulated by:\n",
    "\n",
    "    .. math::\n",
    "        l_i = -\\frac{d}{2} log (2 \\pi) - \\frac{1}{2} log ( |I + r_i S_i^{-1/2} V S_i^{-1/2}| ) -\n",
    "                \\frac{1}{2} z_i^T (I + r_i S_i^{-1/2} V S_i^{-1/2}) ^{-1} z_i\n",
    "\n",
    "    and\n",
    "\n",
    "    .. math::\n",
    "        \\frac{dl}{dV} = S^{-1/2} \\Sigma_i^{-1} (\\Sigma - z_i z_i^T) \\Sigma_i^{-1} S^{-1/2}\n",
    "\n",
    "    Inputs:\n",
    "    V = dxd numpy matrix\n",
    "    z = dxN numpy matrix\n",
    "    S = dxd numpy matrix\n",
    "    u = 1 numpy matrix\n",
    "    r = 1 numpy matrix\n",
    "    f = 1 numpy matrix\n",
    "    logllfunc = function which calculates logll\n",
    "                (uses self._log_ll by default)\n",
    "    gradfunc = function which calculated grad of logll\n",
    "                (uses self._grad_ll_v by default)\n",
    "\n",
    "    Outputs:\n",
    "    -log_ll = 1x1 scalar\n",
    "    -Gvec = dxd numpy matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Unflatten V into a matrix\n",
    "    d = S[0].shape[0]\n",
    "    N = len(S)\n",
    "    \n",
    "    Gvec = np.zeros((N, d, d))\n",
    "    log_ll = np.zeros(N)\n",
    "\n",
    "    # Normalizg variables\n",
    "    V_norm = V\n",
    "    for i in range(N):\n",
    "\n",
    "        Si = S[i]\n",
    "        zi = z[i, :].reshape((d, 1))\n",
    "        ui = u[i]\n",
    "        ri = r[i]\n",
    "\n",
    "        Si = N * Si\n",
    "\n",
    "        log_ll[i] = (1/ui) * _log_ll_vec(V_norm , zi, Si, ri)\n",
    "        Gvec[i, :, :] = (1/ui) * _grad_ll_v(V_norm, zi, Si, ri)\n",
    "\n",
    "    return log_ll.sum() , Gvec.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neglike_wrapper(V, z, S, u, r, f):\n",
    "    \n",
    "    d = S[0].shape[0]\n",
    "    \n",
    "    V = return_to_symmetric(V, d)\n",
    "    \n",
    "    logll, Gvec = neg_logll_grad(V, \n",
    "                               z, S, \n",
    "                               u, r, \n",
    "                               f)\n",
    "    \n",
    "    Gvec = extract_upper_triangle(Gvec)\n",
    "    \n",
    "    return logll, Gvec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'S' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-df23348f6d3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'S' is not defined"
     ]
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-5712ba8a02bc>:37: NumbaPerformanceWarning: \u001b[1m\u001b[1m\u001b[1mnp.dot() is faster on contiguous arrays, called on (array(float64, 2d, A), array(float64, 2d, C))\u001b[0m\u001b[0m\u001b[0m\n",
      "  - (1/2) * np.dot(z.T,Sigma_inv.dot(z))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-11.68651716929529"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_log_ll_vec(V, model.z[0], model.S[0], model.r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-a14bcf696e6f>:32: NumbaPerformanceWarning: \u001b[1m\u001b[1m\u001b[1mnp.dot() is faster on contiguous arrays, called on (array(float64, 2d, C), array(float64, 2d, A))\u001b[0m\u001b[0m\u001b[0m\n",
      "  SSigma_inv = S_inv_root.dot(Sigma_inv)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.33298951,  0.66649537],\n",
       "       [ 0.66649537, -1.33316706]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_grad_ll_v(V, model.z[0], model.S[0], model.r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38631.03860184946 [[-140.90639708  -82.11590935]\n",
      " [ -82.11590935  125.08515464]]\n"
     ]
    }
   ],
   "source": [
    "logll, gvec = neg_logll_grad(V, model.z, model.S, model.u, model.r, model.f)\n",
    "print(logll, gvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-38631.03860184951, array([[ 140.90639708,   82.11590935],\n",
       "        [  82.11590935, -125.08515464]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_logll_grad_basic(V, model.z, model.S, model.u, model.r, model.f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-38631.03860184946, array([ 140.90639708,   82.11590935, -125.08515464]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neglike_wrapper(extract_upper_triangle(V), model.z, model.S, model.u, model.r, model.f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(z, \n",
    "          S,\n",
    "          u,\n",
    "          r,\n",
    "          f,\n",
    "         est_init = None,\n",
    "         printout = True):\n",
    "\n",
    "    \"\"\"\n",
    "    Solves the ldsc problem of infering the V matrix\n",
    "\n",
    "    Inputs:\n",
    "    z = Nx1 numpy matrix\n",
    "    S = dxd numpy matrix\n",
    "    u = 1 numpy matrix\n",
    "    r = 1 numpy matrix\n",
    "    f = 1 numpy matrix\n",
    "\n",
    "    Outputs:\n",
    "    output_matrix = dxd numpy matrix\n",
    "    result = result of scipy solver \n",
    "    \"\"\"\n",
    "    # == Solves our MLE problem == #\n",
    "    n, m = z.shape\n",
    "\n",
    "    if est_init is not None:\n",
    "        # Shape of initial varcov guess\n",
    "        rowstrue = est_init.shape[0] == m\n",
    "        colstrue = est_init.shape[1] == m\n",
    "\n",
    "        if rowstrue & colstrue:\n",
    "            pass\n",
    "        else:\n",
    "            if printout == True:\n",
    "                print(\"Warning: Initial Estimate given is not of the proper dimension\")\n",
    "                print(\"Making 'optimal' matrix\")\n",
    "                print(\"=================================================\")\n",
    "\n",
    "            est_init = np.zeros((m, m))\n",
    "    else:\n",
    "        if printout == True:\n",
    "            print(\"No initial guess provided.\")\n",
    "            print(\"Making 'optimal' matrix\")\n",
    "            print(\"=================================================\")\n",
    "\n",
    "        est_init = np.zeros((m, m))\n",
    "\n",
    "\n",
    "    # exporting for potential later reference\n",
    "#     self.est_init = est_init\n",
    "\n",
    "    # extract array from est init\n",
    "    est_init_array = extract_upper_triangle(est_init) \n",
    "\n",
    "    bounds = extract_bounds(m)     \n",
    "\n",
    "    result = minimize(\n",
    "        neglike_wrapper, \n",
    "        est_init_array,\n",
    "        jac = True,\n",
    "        args = (z, S, u, r, f),\n",
    "        bounds = bounds,\n",
    "        method = 'L-BFGS-B',\n",
    "        options = {'ftol' : 1e-15}\n",
    "    )\n",
    "\n",
    "    output_matrix = return_to_symmetric(result.x, m)\n",
    "\n",
    "    # re-normnalizing output matrix \n",
    "#     self.output_matrix = output_matrix\n",
    "\n",
    "    return output_matrix, result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No initial guess provided.\n",
      "Making 'optimal' matrix\n",
      "=================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.52262128, 0.26207389],\n",
       "        [0.26207389, 0.48484274]]),       fun: 38627.52359063335\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([ 2.43951351e-05, -1.33080442e-05,  7.36192092e-05])\n",
       "   message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "      nfev: 48\n",
       "       nit: 17\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([0.52262128, 0.26207389, 0.48484274]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve(model.z, model.S, model.u, model.r, model.f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
