{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd() + '/..')\n",
    "import sib_ldsc_z as ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "Reading in Data\n",
      "=====================================\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops/from_chr1_to_chr23_start0_end50_run0_p0-0_ab_corr1-0_vb0-25_length2/gen_0_gen_1_phenotype.hdf5\n"
     ]
    }
   ],
   "source": [
    "# == Reading in data == #\n",
    "print(\"=====================================\")\n",
    "print(\"Reading in Data\")\n",
    "print(\"=====================================\")\n",
    "# reading in  data\n",
    "filenames = f\"/disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops/from_chr1_to_chr23_start0_end50_run0_p0-0_ab_corr1-0_vb0-25_length2/gen_0_gen_1_phenotype.hdf5\"\n",
    "\n",
    "files = glob.glob(filenames)\n",
    "\n",
    "file = files[0]\n",
    "print(\"Reading in file: \", file)\n",
    "hf = h5py.File(file, 'r')\n",
    "metadata = hf.get(\"bim\")[()]\n",
    "chromosome = metadata[:, 0]\n",
    "snp = metadata[:, 1]\n",
    "theta  = hf.get('estimate')[()]\n",
    "se  = hf.get('estimate_ses')[()]\n",
    "N = hf.get('N_L')[()]\n",
    "S = hf.get('estimate_covariance')[()]\n",
    "f = hf.get('freqs')[()]\n",
    "\n",
    "# normalizing S\n",
    "sigma2 = hf.get('sigma2')[()]\n",
    "tau = hf.get('tau')[()]\n",
    "phvar = sigma2+sigma2/tau\n",
    "\n",
    "if len(files) > 1:\n",
    "    for file in files[1:]:\n",
    "        print(\"Reading in file: \", file)\n",
    "        hf = h5py.File(file, 'r')\n",
    "        metadata = hf.get(\"bim\")[()]\n",
    "        chromosome_file = metadata[:, 0]  \n",
    "        snp_file = metadata[:, 1]\n",
    "        theta_file  = hf.get('estimate')[()]\n",
    "        se_file  = hf.get('estimate_ses')[()]\n",
    "        S_file = hf.get('estimate_covariance')[()]\n",
    "        f_file = hf.get('freqs')[()]\n",
    "        N_file = hf.get('N_L')[()]\n",
    "\n",
    "        # normalizing S\n",
    "        sigma2 = hf.get('sigma2')[()]\n",
    "        tau = hf.get('tau')[()]\n",
    "\n",
    "        chromosome = np.append(chromosome, chromosome_file, axis = 0)\n",
    "        snp = np.append(snp, snp_file, axis = 0)\n",
    "        theta = np.append(theta, theta_file, axis = 0)\n",
    "        se = np.append(se, se_file, axis = 0)\n",
    "        S = np.append(S, S_file, axis = 0)\n",
    "        f = np.append(f, f_file, axis = 0)\n",
    "        N = np.append(N, N_file, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing dataframe of data\n",
    "zdata = pd.DataFrame({'CHR' : chromosome,\n",
    "                    'SNP' : snp,\n",
    "                    'N' : N,\n",
    "                    \"f\" : f,\n",
    "                    'theta' : theta.tolist(),\n",
    "                    'se' : se.tolist(),\n",
    "                    \"S\" : S.tolist()})\n",
    "\n",
    "\n",
    "zdata['CHR'] = zdata['CHR'].astype(int)\n",
    "zdata['SNP'] = zdata['SNP'].astype(str).str.replace(\"b'\", \"\").str[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Reading in LD Scores == #\n",
    "ldscore_path = \"/disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops/from_chr1_to_chr23_start0_end50_run0_p0-0_ab_corr1-0_vb0-25_length2/ldscores/*[0-9].l2.ldscore.gz\"\n",
    "ldcolnames = [\"CHR\", \"SNP\", \"BP\", \"L2\"]\n",
    "Mfiles = \"/disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops/from_chr1_to_chr23_start0_end50_run0_p0-0_ab_corr1-0_vb0-25_length2/ldscores/*[0-9].l2.M_5_50\"\n",
    "Mcolnames = [\"M\", \"CHR\"]\n",
    "\n",
    "ldscores= ld.read_ldscores(ldscore_path, ldcolnames)\n",
    "nloci = ld.read_mfiles(Mfiles, Mcolnames)\n",
    "\n",
    "# Merging LD scores with main Data Frame\n",
    "main_df = zdata.merge(ldscores, how = \"inner\", on = [\"CHR\", \"SNP\"])\n",
    "\n",
    "# dropping NAs\n",
    "main_df = main_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.shape[0] - zdata.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No initial guess provided.\n",
      "Making Method of Moments Guess\n",
      "=================================================\n",
      "Initial estimate: [22.89196202 48.93274186  0.99863346]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/homedirs/nber/harij/gitrepos/SNIPar/ldsc_reg/multigen_sim/../sib_ldsc_z.py:337: NumbaPerformanceWarning: \u001b[1m\u001b[1m\u001b[1m'@' is faster on contiguous arrays, called on (array(float64, 2d, F), array(float64, 2d, A))\u001b[0m\u001b[0m\u001b[0m\n",
      "  log_ll += (1/ui) * _log_ll(V, zi, Si, li, M)\n",
      "/disk/homedirs/nber/harij/gitrepos/SNIPar/ldsc_reg/multigen_sim/../sib_ldsc_z.py:337: NumbaPerformanceWarning: \u001b[1m\u001b[1m'@' is faster on contiguous arrays, called on (array(float64, 2d, F), array(float64, 2d, A))\u001b[0m\u001b[0m\n",
      "  log_ll += (1/ui) * _log_ll(V, zi, Si, li, M)\n"
     ]
    }
   ],
   "source": [
    "# transforming inputs\n",
    "\n",
    "S = np.array(list(main_df.S)) \n",
    "theta = np.array(list(main_df.theta))\n",
    "f = np.array(list(main_df[\"f\"]))\n",
    "l = np.array(list(main_df[\"L2\"]))\n",
    "u = np.array(list(main_df[\"L2\"]))\n",
    "\n",
    "# M = mfile['M'].sum()\n",
    "M = len(S)\n",
    "\n",
    "effect_estimated = \"direct_plus_population\"\n",
    "\n",
    "S, theta = ld.transform_estimates(effect_estimated, S, theta)\n",
    "\n",
    "# making z value\n",
    "zval = ld.theta2z(theta, S, M = M)\n",
    "\n",
    "# == Initializing model == #\n",
    "model = ld.sibreg(S = S, \n",
    "                z = zval, \n",
    "                l = l,\n",
    "                f = f,\n",
    "                u = u,\n",
    "                M = M) \n",
    "\n",
    "output_matrix, result = model.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "    estimates = {'v1' : output_matrix['v1'],\n",
    "                'v2' : output_matrix['v2'],\n",
    "                'v3' : output_matrix['r']}\n",
    "    \n",
    "    varcovar_mat = np.diag(output_matrix['std_err_mat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05996191, 0.11832532, 0.0013139 ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varcovar_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
